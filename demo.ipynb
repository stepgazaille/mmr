{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pythonrouge.pythonrouge import Pythonrouge\n",
    "from qbsum.corpus import Corpus\n",
    "from qbsum.summarizers import MMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read directories description from file:\n",
    "with open('directories.json') as f:\n",
    "    directories = json.load(f)\n",
    "\n",
    "baseDir = Path(os.getcwd())\n",
    "documentsDir = baseDir / directories['test']['documents']\n",
    "queriesDir = baseDir / directories['test']['queries']\n",
    "referencesDir = baseDir / directories['test']['references']\n",
    "summariesDir = baseDir / directories['test']['summaries']\n",
    "\n",
    "if not summariesDir.is_dir():\n",
    "    os.mkdir(summariesDir)\n",
    "\n",
    "mmrDir = summariesDir/'MMR'\n",
    "if not mmrDir.is_dir():\n",
    "    os.mkdir(mmrDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(documentsDir, queriesDir, referencesDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize summarizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "mmr = MMR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DOC SET 01\n",
      "\tQUERY\t Why did Tesla share prices fell?\n",
      "\tDOC\t What is Tesla without Elon Musk? That was the question Wall Street was asking on Friday as ...\n",
      "\tDOC\t Elon Musk is to step down as chair of Tesla for three years and pay a fine after reaching  ...\n",
      "\tSUM\t ['Last Friday Tesla’s share price was down close to 14% as investors lost confidence.']\n",
      "\tREF\t [['Tesla share prices fell following a SEC suit accusing Musk of fraud.']]\n",
      "\n",
      "DOC SET 02\n",
      "\tQUERY\t Why did Facebook share prices fell?\n",
      "\tDOC\t Time for a recap: Around $36bn has been wiped off Facebook’s market capitalisation, after  ...\n",
      "\tDOC\t Politicians and regulators won’t be the only people who want a word with Mark Zuckerberg.  ...\n",
      "\tSUM\t ['In the circumstances, the severe reaction in the share price is not a surprise.']\n",
      "\tREF\t [[\"Facebook's shares fell following the data breach involving Cambridge Analytica.\"]]\n"
     ]
    }
   ],
   "source": [
    "# For each documents set in corpus:\n",
    "for i in range(len(corpus.queries)):\n",
    "\n",
    "    documentSetName = corpus.documentSetNames[i]\n",
    "\n",
    "    # Create a summary:\n",
    "    summaryFile = documentSetName + '.txt'\n",
    "    summary = mmr.summarize(corpus.documents[i],\n",
    "        corpus.queries[i],\n",
    "        mmrDir/summaryFile,\n",
    "        nbWords=10,\n",
    "        lda=0.9)\n",
    "    candidates.append(summary)\n",
    "    \n",
    "\n",
    "    print(\"\\nDOC SET {}\".format(documentSetName))\n",
    "    print(\"\\tQUERY\\t\", corpus.queries[i])\n",
    "    for document in corpus.documents[i]:\n",
    "        print(\"\\tDOC\\t\", document.text[:90], \"...\")\n",
    "    print(\"\\tSUM\\t\", summary)\n",
    "    print(\"\\tREF\\t\", corpus.references[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ROUGE configuration from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_file_exist': False,\n",
       " 'n_gram': 2,\n",
       " 'ROUGE_SU4': True,\n",
       " 'ROUGE_L': False,\n",
       " 'recall_only': False,\n",
       " 'stemming': True,\n",
       " 'stopwords': True,\n",
       " 'word_level': True,\n",
       " 'length_limit': True,\n",
       " 'length': 10,\n",
       " 'use_cf': False,\n",
       " 'cf': 95,\n",
       " 'scoring_formula': 'average',\n",
       " 'resampling': True,\n",
       " 'samples': 1000,\n",
       " 'favor': True,\n",
       " 'p': 0.5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('rouge_args.json') as f:\n",
    "    rouge_args = json.load(f)\n",
    "rouge_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure pythonrouge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Pythonrouge(summary=candidates, reference=corpus.references,\n",
    "                    summary_file_exist=rouge_args['summary_file_exist'],\n",
    "                    n_gram=rouge_args['n_gram'],\n",
    "                    ROUGE_SU4=rouge_args['ROUGE_SU4'],\n",
    "                    ROUGE_L=rouge_args['ROUGE_L'],\n",
    "                    recall_only=rouge_args['recall_only'],\n",
    "                    stemming=rouge_args['stemming'],\n",
    "                    stopwords=rouge_args['stopwords'],\n",
    "                    word_level=rouge_args['word_level'],\n",
    "                    length_limit=rouge_args['length_limit'],\n",
    "                    length=rouge_args['length'],\n",
    "                    use_cf=rouge_args['use_cf'],\n",
    "                    cf=rouge_args['cf'],\n",
    "                    scoring_formula=rouge_args['scoring_formula'],\n",
    "                    resampling=rouge_args['resampling'],\n",
    "                    samples=rouge_args['samples'],\n",
    "                    favor=rouge_args['favor'],\n",
    "                    p=rouge_args['p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate candidate summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION\n",
      "\tROUGE-1-R\t 0.25\n",
      "\tROUGE-1-F\t 0.27693\n",
      "\tROUGE-2-R\t 0.14285\n",
      "\tROUGE-2-F\t 0.15384\n",
      "\tROUGE-SU4-R\t 0.10938\n",
      "\tROUGE-SU4-F\t 0.12519\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEVALUATION\")\n",
    "score = rouge.calc_score()\n",
    "for key in score.keys():\n",
    "    print(\"\\t\" + key + \"\\t {}\".format(score[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
